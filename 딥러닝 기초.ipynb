{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0729 신경망\n",
    "## 신경망 접하기- 흑백 손글씨 숫자 이미지 10개의 범주로 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 케라스에서 MNIST 데이터셋 적재하기\n",
    "from keras.datasets import mnist \n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_images와 train_labels = 모델이 학습할 훈련 세트\n",
    "\n",
    "test_images와 test_labels = 모델 테스트 할 때 쓸 테스트 세트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#훈련 데이터 살펴보기\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#테스트 데이터 살펴보기\n",
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 데이터를 네트워크에 주입하여 학습시키고 test_images에 대한 예측을 네트워크에 요청한 뒤, 이 예측이 test_labels와 맞는지 확인한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#신경망 구조\n",
    "from keras import models\n",
    "from keras import layers\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='relu', input_shape= (28*28,)))\n",
    "network.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "대부분의 딥러닝은 간단한 층을 연결하여 구성되어 있고, 점진적으로 데이터를 정제하는 형태를 띠고 있다. 딥러닝 모델은 데이터 정제 필터가 연속되어 있는 여과기와 같다.\n",
    "\n",
    "신경망이 훈련 준비를 마치려면 컴파일 단계가 필요한데, 여기 포함될 세 가지 요소로 손실 함수loss, 옵티마이저optimizer, 모니터링 지표metrics가 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "'''categorical_crossentropy는 손실 함수. \n",
    "훈련하는 동안 미니 배치 SGD를 통해 최소화된다.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[0,255] 사이의 값인 unit8타입의 배열로 저장되어 있는 훈련 이미지를 0과 1 사이의 값을 가지는 float32 타입의 배열로 바꾼다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#레이블을 범주형으로 인코딩한다.\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "케라스에서는 fit 메서드를 호출하여 훈련 데이터에 모델을 학습시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 4s 5ms/step - loss: 0.2567 - accuracy: 0.9261\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1032 - accuracy: 0.9695\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0681 - accuracy: 0.9798\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0503 - accuracy: 0.9850\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0379 - accuracy: 0.9885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16fb76ed850>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(train_images, train_labels, epochs=5, batch_size=128)\n",
    "#epochs= 전체 훈련 데이터에 수행되는 각 반복\n",
    "''' 네트워크가 128개 샘플식 미니 배치로 훈련 데이터를 5번 반복함.\n",
    "각 반복마다 신경망이 배치에서 손실에 대한 가중치의 그래디언트를 계산하고 거기 맞춰 가중치를 업데이트함.\n",
    "5번의 에포크동안 2345번의 그래디언트 업데이트..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텐서\n",
    "최근의 모든 머신 러닝 시스템을 일반적으로 텐서를 기본 데이터 구조로 사용한다. 텐서는 머신 러닝의 기본 구성 요소이다.\n",
    "## 텐서란? \n",
    "데이터를 위한 컨테이너, 거의 항상 수치형 데이터를 다루므로 숫자를 위한 컨테이너이다. 행렬은 2D 텐서이며, 하나의 숫자만 담고 있는 스칼라는 0차원 덴서라고 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#스칼라\n",
    "import numpy as np\n",
    "x= np.array(12)\n",
    "x.ndim #몇차원 텐서인지 알 수 있는 메서드이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#벡터\n",
    "#숫자의 배열, 하나의 축을 가진다\n",
    "x = np.array([12,3,6,14,7])\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "벡터와 텐서 혼동하면 안됨: [12,3,6,14,7]의 경우 5차원 벡터지만 5D 텐서(랭크5 텐서)라고는 할 수 없다. \n",
    "\n",
    "위의 5D 벡터는 하나의 축을 따라 5개의 차원을 가진 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#행렬(백터의 배열, 2D 텐서)\n",
    "x= np.array([[5, 78, 2, 34, 0], \n",
    "            [6, 79, 3, 35, 1], \n",
    "            [7, 80, 4, 36, 2]])\n",
    "x.ndim\n",
    "#x의 첫번째행=[5,78,2,34,0], x의 첫번째열=[5,6,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3D 텐서\n",
    "x = np.array([[[5, 78, 2, 34, 0], \n",
    "                   [6, 79, 3, 35, 1], \n",
    "                   [7, 80, 4, 36, 2]], \n",
    "                  [[5, 78, 2, 34, 0], \n",
    "                   [6, 79, 3, 35, 1], \n",
    "                   [7, 80, 4, 36, 2]], \n",
    "                  [[5, 78, 2, 34, 0], \n",
    "                   [6, 79, 3, 35, 1], \n",
    "                   [7, 80, 4, 36, 2]]]) \n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3D 텐서들을 하나의 배열로 합치면 4D 텐서가 된다. 딥러닝에서는 보통 0D에서 4D까지의 텐서를 다루며, 동영상 데이터를 다룰 때 5D까지 가기도 한다.\n",
    "\n",
    "## 텐서는 3개의 핵심 속성으로 정의된다.\n",
    "* 축의 개수(랭크)\n",
    "* 크기(축을 따라 얼마나 많은 차원이 있는지를 나타낸 파이썬의 튜플. 위의 3D 텐서의 크기는 (3,3,5)\n",
    "* 데이터 타입(텐서에 포함된 데이터의 타입. NumPy에서는 Dtype에 저장된다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "#MNIST 데이터셋의 축의 갯수는 3개\n",
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "print(train_images.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "#배열의 크기\n",
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n"
     ]
    }
   ],
   "source": [
    "#데이터 타입=8비트 정수\n",
    "print(train_images.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 배열은 28*28 크기의 8비트 정수 행렬 6만개가 있는 배열(3D 텐서)이다. 각 행렬은 하나의 흑백 이미지고, 행렬의 각 원소는 0에서 255 사이의 값을 가진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#5번째 이미지 출력\n",
    "digit = train_images[4]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "#넘파이로 텐서 조작하기\n",
    "my_slice = train_images[10:100] \n",
    "#아래 두 방법으로 표기해도 동일 결과 출력\n",
    "#my_slice = train_images[10:100, :, :]\n",
    "#my_slice = train_images[10:100, 0:28, 0:28]\n",
    "#11번째에서 101번째까지(101번쨰는 포함X) 선택하여 (90,28,28) 크기의 배열 만들기\n",
    "print(my_slice.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딥러닝 모델은 한 번에 전체 데이터셋을 처리하지 않는다. 대신 데이터를 작은 배치로 나눈다.\n",
    "\n",
    "* 첫 번째 배치 batch = train_images[:128]\n",
    "* 두 번째 배치 batch = train_images[128:256]\n",
    "* n번째 배치 batch = train_images[128*n:128*(n+1)]\n",
    "\n",
    "이런 배치 데이터를 다룰 때는 첫 번째 축을 배치 축 또는 배치 차원이라고 부른다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서의 몇 가지 예\n",
    "\n",
    "* 벡터 데이터- (samples, features) 크기의 2D 텐서\n",
    "* 시계열 데이터 또는 시퀀스 데이터:(samples, timesteps, features) 크기의 3D 텐서\n",
    "* 이미지: (samples, height, width, channels) 또는 (samples, channels, height, width) 크기의 4D 텐서\n",
    "* 동영상: (samples, frames, height, width, channels) 또는 (samples, frames, channels, height, width) 크기의 5D 텐서"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "벡터 데이터- 대부분의 경우. 첫 번째 축: 샘플 축, 두 번째 축: 특성 축\n",
    "\n",
    "시계열 데이터- 데이터에서 시간이나 연속된 순서가 중요할 때 시간 축을 포함하여 저장. 관례적으로 시간 축은 항상 두 번째(인덱스1) 축이다.\n",
    "\n",
    "이미지 데이터- 높이, 너비, 컬러채널의 3차원으로 이루어진 이미지 샘플 갯수. 채널 마지막 방식과 채널 우선 방식 두 가지가 있음\n",
    "\n",
    "비디오 데이터- 프레임이 (height, width, color_depth)의 3D 텐서로 저장될 수 있기 때문에 프레임의 연속은 (frames, height, width, color_depth)의 4D 텐서로 저장될 수 있음. 여러 비디오의 배치일 경우 5D 텐서로 저장될 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텐서 연산\n",
    "\n",
    "심층 신경망이 학습한 모든 변환을 수치 데이터 텐서에 적용하는 몇 종류의 텐서 연산tensor operation으로 나타낼 수 있다. 텐서 덧셈이나 텐서 곱셈 등이 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.dense.Dense at 0x16fb78ee340>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#케라스 층 생성\n",
    "keras.layers.Dense(512, activation='relu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 층은 2D 텐서를 입력으로 받고 입력 텐서의 새로운 표현인 또 다른 2D 텐서를 반환하는 함수처럼 해석할 수 있다.\n",
    "구체적으로 보면 이 함수는 다음과 같다.\n",
    "\n",
    "output = relu(dot(w,input)+b)\n",
    "\n",
    "텐서 연산 3개\n",
    "* 입력 텐서와 텐서 W 사이의 점곱(dot) \n",
    "* 점곱의 결과인 2D 텐서와 벡터 b 사이의 덧셈(+)\n",
    "* relu(렐루) 연산 (max(x,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "렐루 함수와 덧셈은 원소별 연산으로, 텐서에 있는 각 원소에 독립적으로 적용된다. 파이썬으로 단순한 원소별 연산을 구현한다면 for 반복문을 사용할 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#원소별 연산\n",
    "def naive_relu(x):\n",
    "    assert len(x.shape) == 2    # x=2D 넘파이 배열만\n",
    "    x = x.copy()     # 입력 텐서 자체를 바꾸지 않도록 복사\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] = max(x[i, j], 0)\n",
    "    return x\n",
    "\n",
    "'''덧셈, 곱셈, 뺄셈도 동일하다.\n",
    "def naive_add(x, y):\n",
    "    assert len(x.shape) == 2  # x와 y는 2D 넘파이 배열\n",
    "    assert x.shape == y.shape\n",
    "\n",
    "    x = x.copy()    # 입력 텐서 자체를 바꾸지 않도록 복사\n",
    "        for i in range(x.shape[0]):\n",
    "            for j in range(x.shape[1]):\n",
    "                x[i, j] += y[i, j]\n",
    "    return x'''\n",
    "#물론 넘파이 쓰면 저런 연산들을 바로 처리할 수 있음.\n",
    "#원소별 덧셈 z= x+y\n",
    "#z=원소별 렐루 np.maximum(z, 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#브로드캐스팅\n",
    "'''크기가 다른 두 텐서가 더해질 때-\n",
    "작은 텐서가 큰 텐서의 크기에 맞추어 브로드캐스팅된다.'''\n",
    "import numpy as np\n",
    "x = np.random.random((64, 3, 32, 10)) \n",
    "# x는 (64, 3, 32, 10) 크기의 랜덤 텐서\n",
    "y = np.random.random((32, 10))        \n",
    "# y는 (32, 10) 크기의 랜덤 텐서\n",
    "z = np.maximum(x, y)\n",
    "# 출력 z 크기는 x와 동일하게 (64, 3, 32, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#텐서 점곱(내적)\n",
    "'''텐서 곱셈이라고도 불림.'''\n",
    "import numpy as np\n",
    "#z = np.dot(x, y)\n",
    "\n",
    "#z = x · y\n",
    "\n",
    "#점곱 연산이란?\n",
    "def naive_vector_dot(x, y):\n",
    "    assert len(x.shape) == 1  # x와 y는 넘파이 벡터\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[0] == y.shape[0]\n",
    "\n",
    "    z = 0.\n",
    "    for i in range(x.shape[0]):\n",
    "        z += x[i] * y[i]\n",
    "    return z\n",
    "'''두 벡터의 점곱은 스칼라가 되므로, 원소 개수가 같은 \n",
    "벡터끼리 점곱이 가능함'''\n",
    "\n",
    "def naive_matrix_dot(x, y):\n",
    "    assert len(x.shape) == 2   # x와 y는 넘파이 행렬입니다.\n",
    "    assert len(y.shape) == 2\n",
    "    assert x.shape[1] == y.shape[0]  # x의 두 번째 차원이 y의 첫 번째 차원과 같아야 합니다!\n",
    "\n",
    "    z = np.zeros((x.shape[0], y.shape[1]))  # 이 연산은 0이 채워진 특정 크기의 벡터를 만듭니다.\n",
    "    for i in range(x.shape[0]):     # x의 행을 반복합니다.\n",
    "        for j in range(y.shape[1]): # y의 열을 반복합니다.\n",
    "            row_x = x[i, :]\n",
    "            column_y = y[:, j]\n",
    "            z[i, j] = naive_vector_dot(row_x, column_y)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n"
     ]
    }
   ],
   "source": [
    "#텐서 크기 변환\n",
    "'''텐서의 크기를 변환한다는 것은 특정 크기에 맞게 열과\n",
    "행을 재배열한다는 뜻이다. \n",
    "당연히 크기가 변환된 텐서는 원래 텐서랑 원소 개수가 동일함!\n",
    "'''\n",
    "x = np.array([[0., 1.],\n",
    "                  [2., 3.],\n",
    "                  [4., 5.]])\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [5.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2D 텐서의 크기를 (6,1)로 변환\n",
    "x = x.reshape((6, 1))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 2.],\n",
       "       [3., 4., 5.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2D 텐서의 크기를 (2,3)로 변환\n",
    "x = x.reshape((2, 3))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 300)\n"
     ]
    }
   ],
   "source": [
    "#전치행렬 크기변환\n",
    "x = np.zeros((300, 20))\n",
    "x = np.transpose(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 신경망은 전체적으로 텐서 연산의 연결로 구성된 것이고, 모든 텐서 연산은 입력 데이터의 기하학적 변환임을 배웠습니다. 단순한 단계들이 길게 이어져 구현된 신경망을 고차원 공간에서 매우 복잡한 기하학적 변환을 하는 것으로 해석할 수 있습니다.\n",
    "\n",
    "> 3D라면 다음 비유가 이해하는 데 도움이 될 것입니다. 하나는 빨간색이고 다른 하나는 파란색인 2개의 색종이가 있다고 가정합시다. 두 장을 겹친 다음 뭉쳐서 작은 공으로 만듭니다. 이 종이 공이 입력 데이터고 색종이는 분류 문제의 데이터 클래스입니다. 신경망(또는 다른 머신 러닝 알고리즘)이 해야 할 일은 종이 공을 펼쳐서 두 클래스가 다시 깔끔하게 분리되는 변환을 찾는 것입니다. 손가락으로 종이 공을 조금씩 펼치는 것처럼 딥러닝을 사용하여 3D 공간에서 간단한 변환들을 연결해서 이를 구현합니다.\n",
    "종이 공을 펼치는 것이 머신 러닝이 하는 일입니다. 복잡하고 심하게 꼬여 있는 데이터의 매니폴드에 대한 깔끔한 표현을 찾는 일입니다. 이쯤이면 왜 딥러닝이 이런 작업에 뛰어난지 알았을 것입니다. 기초적인 연산을 길게 연결하여 복잡한 기하학적 변환을 조금씩 분해하는 방식이 마치 사람이 종이 공을 펼치기 위한 전략과 매우 흡사하기 때문입니다.\n",
    "\n",
    "[출처](https://tensorflow.blog/%ec%bc%80%eb%9d%bc%ec%8a%a4-%eb%94%a5%eb%9f%ac%eb%8b%9d/2-3-%ec%8b%a0%ea%b2%bd%eb%a7%9d%ec%9d%98-%ed%86%b1%eb%8b%88%eb%b0%94%ed%80%b4-%ed%85%90%ec%84%9c-%ec%97%b0%ec%82%b0/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 신경망의 엔진\n",
    "\n",
    "위의 예제에 있는 각 층은 입력 데이터를 이렇게 변환한다.\n",
    "\n",
    "output = relu(dot(W, input) * b)\n",
    "\n",
    "> 이 식에서 텐서 W와 b는 가중치 또는 훈련되는 파라미터라고 부른다. \n",
    "이런 가중치에는 훈련 데이터를 신경망에 노출시켜서 학습된 정보가 담겨 있다.\n",
    "초기에는 가중치 행렬이 난수(무작위 초기화 단계)지만\n",
    "피드백 신호에 기초하여 가중치가 점진적으로 조정됨. 이것을 훈련이라고 하며\n",
    "훈련이야말로 머신 러닝 학습의 핵심!!!\n",
    "\n",
    "훈련은 훈련 반복 루프 안에서 일어난다.\n",
    "1. 훈련 샘플 x와 이에 상응하는 타깃 y의 배치 추출\n",
    "2. x 사용해서 신경망 실행하고 예측 y_pred 구하기\n",
    "3. 예측이랑 실제 y의 차이를 측정(손실 계산)\n",
    "4. 배치에 대한 손실이 감소되도록 신경망의 모든 가중치 업뎃!!\n",
    "\n",
    "이순서임\n",
    "이러다보면 손실 작아짐\n",
    "\n",
    "## 근데 이 가중치 어디를 얼마나 업뎃해야 할지 어케 알음?\n",
    "\n",
    "간단한 방법은 가중치를 하나씩 늘였다 줄였다 하는거지만\n",
    "어느세월에 하겠음. . .\n",
    "신경망에 사용된 모든 연산이 미분 가능하다는 점을 사용해서\n",
    "가중치에 대한 손실의 미분 결과(이하 그래디언트)를 계산하는게 훨씬 낫다!!\n",
    "그래디언트의 반대방향으로 가중치 옮기면 손실 작아질것\n",
    "\n",
    "### 미분이 가능하다? > 변화율을 유도할 수 있다.\n",
    "손실 함수 f(x)=y의 경우 연속함수이므로 x를 조금 바꾸면 y가 조금 바뀔 것이다.\n",
    "여기서 x를 작은 값 epsilon_x만큼 증가시킨다 치면 y는 epsilon_y만큼 바뀐다고 할 수 있다.\n",
    "\n",
    "> f(x + epsilon_x) = y + epsilon_y\n",
    "\n",
    "또 이 함수가 매끈매끈해서 epsilon_x가 충분히 작으면 어떤 포인트 p에서 기울기 a의 선형 함수로 f를 근사할 수 있 어쩌고 \n",
    "\n",
    "대충 미분해서 기울기 a 구하고 a가 변화율이니 여기에 맞춰서 이동하면 f(x) 감소 가능하단소리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그래디언트는 텐서 연산의 변화율이다.\n",
    "입력 벡터 x, 행렬 W, 타깃 y와 손실 함수 loss가 있다고 치면\n",
    "W를 사용하여 예측과 손실을 계산할 수 있다.\n",
    "\n",
    "> y_pred = dot(W, x)\n",
    "loss_value = loss(y_pred, y)\n",
    "\n",
    "입력데이터 x와 y가 고정되어 있다면 이 함수는 W를 손실 값에 매핑하는 함수로 볼 수 있다.\n",
    "loss_value = f(w)\n",
    "대충 위에서 한 말 보면 생각나겠지만 이것도 변화율을 구해서 그 반대 방향으로 W를 움직이면 f(w), loss value를 줄일 수 있단 말임\n",
    "\n",
    "> W1 = W0 - step * gradient(f)(W0)(step는 스케일을 조정하는 값)\n",
    "\n",
    "이렇게 업뎃됨\n",
    "\n",
    "함수의 최솟값은 변화율이 0인 지점이므로 \n",
    "## 우리가 할 일: 변화율이 0이 되는 지점을 모두 찾고 이 중에서 어디가 제일 함숫값이 작게 나오는지 확인하기\n",
    "\n",
    "위의 1. 2. 3. 4. 써놓은 방법은 가중치 개수가 두세개면 모르겠는데\n",
    "실제 신경망에선 파라미터가 최소 수천 개는 된다...\n",
    "\n",
    "언제 다하고앉아있음?\n",
    "\n",
    "그 대신 이렇게 하면됨\n",
    "1. 훈련 샘플 x와 이에 상응하는 타깃 y의 배치 추출\n",
    "2. x 사용해서 신경망 실행하고 예측 y_pred 구하기\n",
    "3. 예측이랑 실제 y의 차이를 측정(손실 계산)\n",
    "4. 신경망의 파라미터(weight)에 대한 손실 함수의 그래디언트 계산(역방향 패스)\n",
    "5. 그래디언트의 반대 방향으로 파라미터를 조금 이동시키기\n",
    "\n",
    "이걸 미니 배치 확률적 경사 하강법(미니 배치 SGD)이라고 부른다.\n",
    "확률적이란 단어는 각 배치 데이터가 무작위로 선택된다는 의미.\n",
    "\n",
    "이터레이션마다 하나의 샘플과 하나의 타깃을 뽑으면 진정한 SGD이고 가용한 모든 데이터를 사용하여 반복할 시 배치 SGD라고 부른다. 이건 더 정확하지만 비용이 많이 듦\n",
    "\n",
    "적절한 크기의 미니 배치를 쓰는 것이 효율적 절충안이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "업데이트할 다음 가중치를 계산할 때 그래디언트 값만 보지 않고 이전에 업데이트된 가중치를 여러 다른 방식으로 고려하는 SGD 변종이 여럿 있다. 모멘텀을 사용한 SGD,Adagrad,RMSProp 등 이런 변종들을 모두 옵티마이저라고 부른다. \n",
    "\n",
    "특히 모멘텀 개념은 아주 중요하다. 모멘텀은 SGD에 있는 2개의 문제점인 수렴 속도와 지역 최솟값을 해결한다.\n",
    "(우리는 일정 부분에서만 최소의 값을 가지는 지역 최솟값이 아니라, 전체 부분에서 가장 작은 값인 전역 최솟값을 찾아야 하기 때문에)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
