{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"케라스- 딥러닝 모델을 간편하게 만들고 훈련시킬 수 있는,\n파이썬을 위한 딥러닝 프레임워크\n\n케라스의 작업 흐름\n1. 입력 텐서와 타깃 텐서로 이루어진 훈련 데이터 정의\n2. 입력과 타깃을 매핑하는 층으로 이루어진 네트워크(또는 모델) 정의\n3. 손실 함수, 옵티마이저, 모니터링하기 위한 측정 지표를 선택하여 학습 과정 설정\n4. 훈련 데이터에 대해 모델의 fit() 메서드를 반복적으로 호출","metadata":{}},{"cell_type":"code","source":"#예시\nfrom keras import layers\n\nlayer = layers.Dense(32, input_shape=(784,))#32개의 유닛으로 된 밀집 층","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-12T11:11:03.815471Z","iopub.execute_input":"2022-07-12T11:11:03.815899Z","iopub.status.idle":"2022-07-12T11:11:13.685203Z","shell.execute_reply.started":"2022-07-12T11:11:03.815815Z","shell.execute_reply":"2022-07-12T11:11:13.684086Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"첫 번째 차원이 784인 2D 텐서만 입력으로 받는 층을 만들었다.\n이 층은 첫 번째 차원 크기가 32로 변환된 텐서를 출력할 것이다.\n그러므로 이 층의 하위 층은 32차원의 벡터를 입력으로 받아야 한다.","metadata":{}},{"cell_type":"code","source":"from keras import models\n\nmodel = models.Sequential()\nmodel.add(layers.Dense(32, activation='relu', input_shape=(784,)))\nmodel.add(layers.Dense(10, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2022-07-12T11:43:01.995291Z","iopub.execute_input":"2022-07-12T11:43:01.995736Z","iopub.status.idle":"2022-07-12T11:43:02.023723Z","shell.execute_reply.started":"2022-07-12T11:43:01.995702Z","shell.execute_reply":"2022-07-12T11:43:02.022608Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# 같은 모델을 함수형 API 사용하여 만들어 보기\ninput_tensor = layers.Input(shape=(784,))\nx = layers.Dense(32, activation='relu')(input_tensor)\noutput_tensor = layers.Dense(10, activation='softmax')(x)\n\nmodel = models.Model(inputs=input_tensor, outputs=output_tensor)","metadata":{"execution":{"iopub.status.busy":"2022-07-12T11:43:33.890202Z","iopub.execute_input":"2022-07-12T11:43:33.891326Z","iopub.status.idle":"2022-07-12T11:43:33.915379Z","shell.execute_reply.started":"2022-07-12T11:43:33.891285Z","shell.execute_reply":"2022-07-12T11:43:33.914154Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#컴파일 단계에서 학습 과정 설정\n#여기에서 옵티마이저, 손실함수, 측정 지표 지정함\nfrom tensorflow.keras import optimizers\n\nmodel.compile(optimizer=optimizers.RMSprop(lr=0.001),\n              loss='mse',\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-07-12T11:46:24.726204Z","iopub.execute_input":"2022-07-12T11:46:24.726571Z","iopub.status.idle":"2022-07-12T11:46:25.174446Z","shell.execute_reply.started":"2022-07-12T11:46:24.726541Z","shell.execute_reply":"2022-07-12T11:46:25.173397Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#입력 데이터의 넘파이 배열과 이에 상응하는 타깃 데이터를 \n#모델의 fit() 메서드에 전달하면 학습 과정이 이루어진다.\n\n#model.fit(input_tensor, target_tensor, batch_size=128, epochs=10)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#영화 리뷰 분류: 이진 분류 예제\n#리뷰 텍스트를 기반으로 영화 리뷰를 긍정과 부정으로 분류\n\n#데이터셋 불러오기\ndef load_data(path='../input/imdbdata/imdb.npz',\n              num_words=None,\n              skip_top=0,\n              maxlen=None,\n              seed=113,\n              start_char=1,\n              oov_char=2,\n              index_from=3,\n              **kwargs):\n    \n    path=\"../input/imdbdata/imdb.npz\"\n    with np.load(path, allow_pickle=True) as f:\n        x_train, labels_train = f['x_train'], f['y_train']\n        x_test, labels_test = f['x_test'], f['y_test']\n\n    rng = np.random.RandomState(seed)\n    indices = np.arange(len(x_train))\n    rng.shuffle(indices)\n    x_train = x_train[indices]\n    labels_train = labels_train[indices]\n\n    indices = np.arange(len(x_test))\n    rng.shuffle(indices)\n    x_test = x_test[indices]\n    labels_test = labels_test[indices]\n\n    if start_char is not None:\n        x_train = [[start_char] + [w + index_from for w in x] for x in x_train]\n        x_test = [[start_char] + [w + index_from for w in x] for x in x_test]\n    elif index_from:\n        x_train = [[w + index_from for w in x] for x in x_train]\n        x_test = [[w + index_from for w in x] for x in x_test]\n\n    if maxlen:\n        x_train, labels_train = _remove_long_seq(maxlen, x_train, labels_train)\n        x_test, labels_test = _remove_long_seq(maxlen, x_test, labels_test)\n        if not x_train or not x_test:\n            raise ValueError('After filtering for sequences shorter than maxlen=' +\n                             str(maxlen) + ', no sequence was kept. '\n                             'Increase maxlen.')\n\n    xs = np.concatenate([x_train, x_test])\n    labels = np.concatenate([labels_train, labels_test])\n\n    if not num_words:\n        num_words = max(max(x) for x in xs)\n\n    if oov_char is not None:\n        xs = [\n            [w if (skip_top <= w < num_words) else oov_char for w in x] for x in xs\n        ]\n    else:\n        xs = [[w for w in x if skip_top <= w < num_words] for x in xs]\n\n    idx = len(x_train)\n    x_train, y_train = np.array(xs[:idx],dtype=object), np.array(labels[:idx])\n    x_test, y_test = np.array(xs[idx:],dtype=object), np.array(labels[idx:])\n\n    return (x_train, y_train), (x_test, y_test)\n\n  #훈련 데이터에서 제일 자주 나타나는 단어 1만 개만 사용\n(train_data, train_labels), (test_data, test_labels) = load_data(num_words=10000)","metadata":{"execution":{"iopub.status.busy":"2022-07-12T13:16:51.119286Z","iopub.execute_input":"2022-07-12T13:16:51.119706Z","iopub.status.idle":"2022-07-12T13:16:57.245442Z","shell.execute_reply.started":"2022-07-12T13:16:51.119673Z","shell.execute_reply":"2022-07-12T13:16:57.244311Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"#train_data와 test_data는 리뷰의 목록이다. 각 리뷰는 단어 인덱스의 리스트.\n#train_labels와 test_labels는 부정을 나타내는 0과 긍정을 나타내는 1의 리스트.\ntrain_labels","metadata":{"execution":{"iopub.status.busy":"2022-07-12T13:26:33.385656Z","iopub.execute_input":"2022-07-12T13:26:33.386054Z","iopub.status.idle":"2022-07-12T13:26:33.392703Z","shell.execute_reply.started":"2022-07-12T13:26:33.386021Z","shell.execute_reply":"2022-07-12T13:26:33.391535Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"#가장 자주 등장하는 단어 1만개로 제한했기 때문에\n#단어 인덱스는 10000을 넘지 않음\nmax([max(sequence) for sequence in train_data])","metadata":{"execution":{"iopub.status.busy":"2022-07-12T13:27:14.546056Z","iopub.execute_input":"2022-07-12T13:27:14.546626Z","iopub.status.idle":"2022-07-12T13:27:14.665868Z","shell.execute_reply.started":"2022-07-12T13:27:14.546587Z","shell.execute_reply":"2022-07-12T13:27:14.664720Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"신경망에 숫자 리스트를 주입할 수는 없다. 리스트를 텐서로 바꿔야 한다.\n여기서는 리스트를 원-핫 인코딩하여 0과 1의 벡터로 변환한다.","metadata":{}},{"cell_type":"code","source":"#정수 시퀀스를 이진 행렬로 인코딩\nimport numpy as np\n\ndef vectorize_sequences(sequences, dimension=10000):\n    # 크기가 (len(sequences), dimension)이고 모든 원소가 0인 행렬을 만든다.\n    results = np.zeros((len(sequences), dimension))\n    for i, sequence in enumerate(sequences):\n        results[i, sequence] = 1. # results[i]에서 특정 인덱스의 위치를 1로 만든다.\n    return results\n\nx_train = vectorize_sequences(train_data) # 훈련 데이터를 벡터로 변환\nx_test = vectorize_sequences(test_data) # 테스트 데이터를 벡터로 변환","metadata":{"execution":{"iopub.status.busy":"2022-07-12T13:34:49.026177Z","iopub.execute_input":"2022-07-12T13:34:49.027373Z","iopub.status.idle":"2022-07-12T13:34:55.402461Z","shell.execute_reply.started":"2022-07-12T13:34:49.027278Z","shell.execute_reply":"2022-07-12T13:34:55.401325Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"x_train[0]","metadata":{"execution":{"iopub.status.busy":"2022-07-12T13:35:05.528586Z","iopub.execute_input":"2022-07-12T13:35:05.529835Z","iopub.status.idle":"2022-07-12T13:35:05.542046Z","shell.execute_reply.started":"2022-07-12T13:35:05.529788Z","shell.execute_reply":"2022-07-12T13:35:05.540567Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"y_train = np.asarray(train_labels).astype('float32')\ny_test = np.asarray(test_labels).astype('float32')","metadata":{"execution":{"iopub.status.busy":"2022-07-12T13:35:41.988804Z","iopub.execute_input":"2022-07-12T13:35:41.989185Z","iopub.status.idle":"2022-07-12T13:35:41.995263Z","shell.execute_reply.started":"2022-07-12T13:35:41.989153Z","shell.execute_reply":"2022-07-12T13:35:41.994003Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"입력 데이터= 벡터\n레이블= 스칼라\nDense 층을 쌓을 때 결정해야 하는 두가지:\n* 얼마나 많은 층을 사용할 것인가?\n* 각 층에 얼마나 많은 은닉 유닛을 둘 것인가?\n\n여기서는 16개의 은닉 유닛을 가진 2개의 층을 둘 것이며,\n세 번째 층은 현재 리뷰의 감정을 스칼라 값의 예측으로 출력한다. \n은닉층의 활성화 함수로는 relu를 사용하고 마지막 층은 시그모이드를 사용한다.","metadata":{}},{"cell_type":"code","source":"from keras import models\nfrom keras import layers\n\nmodel = models.Sequential()\nmodel.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\nmodel.add(layers.Dense(16, activation='relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))","metadata":{"execution":{"iopub.status.busy":"2022-07-12T13:41:36.679553Z","iopub.execute_input":"2022-07-12T13:41:36.680328Z","iopub.status.idle":"2022-07-12T13:41:36.732764Z","shell.execute_reply.started":"2022-07-12T13:41:36.680286Z","shell.execute_reply":"2022-07-12T13:41:36.731709Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"손실 함수와 옵티마이저를 선택한다. 이진 분류 문제고 신경망의 출력이 확률이기 때문에 binary_crossentropy 손실이 적합하다. MSE도 사용할 수 있긴 하지만 확률을 출력하는 모델을\n만들 땐 크로스엔트로피가 최선이라고 한다.\n\n크로스엔트로피는 확률 분포 간의 차이를 측정한다. 여기서는 원본 분포와 예측 분포 사이를 측정한다.\n옵티마이저는 rmsprop를 쓴다는데 뭔지모르겠다","metadata":{}},{"cell_type":"code","source":"#모델 컴파일\n#케라스에 rmsprop, binary_crossentropy, accuracy가 포함되어 있어서\n#문자열로 지정 가능함\nmodel.compile(optimizer='rmsprop',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-07-12T13:45:38.900393Z","iopub.execute_input":"2022-07-12T13:45:38.900830Z","iopub.status.idle":"2022-07-12T13:45:38.912614Z","shell.execute_reply.started":"2022-07-12T13:45:38.900797Z","shell.execute_reply":"2022-07-12T13:45:38.911527Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"#옵티마이저의 매개변수를 바꿔야 할 때 다음 코드를 사용\nfrom tensorflow.keras import optimizers\nmodel.compile(optimizer=optimizers.RMSprop(lr=0.001),\n              loss='binary_crossentropy',\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-07-12T13:46:28.784231Z","iopub.execute_input":"2022-07-12T13:46:28.785289Z","iopub.status.idle":"2022-07-12T13:46:28.797202Z","shell.execute_reply.started":"2022-07-12T13:46:28.785242Z","shell.execute_reply":"2022-07-12T13:46:28.796185Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"#자신만의 손실 함수나 측정 함수를 전달해야 할 때 다음 코드를 사용\nfrom keras import losses\nfrom keras import metrics\n\nmodel.compile(optimizer=optimizers.RMSprop(lr=0.001),\n              loss=losses.binary_crossentropy,\n              metrics=[metrics.binary_accuracy])","metadata":{"execution":{"iopub.status.busy":"2022-07-12T13:47:29.228564Z","iopub.execute_input":"2022-07-12T13:47:29.229004Z","iopub.status.idle":"2022-07-12T13:47:29.241237Z","shell.execute_reply.started":"2022-07-12T13:47:29.228963Z","shell.execute_reply":"2022-07-12T13:47:29.240406Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"# 훈련 검증\n모델 정확도를 측정하기 위해 원본 훈련 데이터에서 10000개의 셈플을 떼어\n검증 세트를 만든다.","metadata":{}},{"cell_type":"code","source":"x_val = x_train[:10000]\npartial_x_train = x_train[10000:]\ny_val = y_train[:10000]\npartial_y_train = y_train[10000:]","metadata":{"execution":{"iopub.status.busy":"2022-07-12T13:48:26.263127Z","iopub.execute_input":"2022-07-12T13:48:26.263501Z","iopub.status.idle":"2022-07-12T13:48:26.268487Z","shell.execute_reply.started":"2022-07-12T13:48:26.263471Z","shell.execute_reply":"2022-07-12T13:48:26.267635Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"#모델에서 512개의 샘플씩 미니 배치를 만들어 20번의 에포크 동안 훈련\n#(x_train과 y_train 텐서에 있는 모든 샘플에 대해 20번 반복)\nmodel.compile(optimizer='rmsprop',\n              loss='binary_crossentropy',\n              metrics=['acc'])\n\nhistory = model.fit(partial_x_train,\n                    partial_y_train,\n                    epochs=20,\n                    batch_size=512,\n                    validation_data=(x_val, y_val))","metadata":{"execution":{"iopub.status.busy":"2022-07-12T13:49:52.280106Z","iopub.execute_input":"2022-07-12T13:49:52.280502Z","iopub.status.idle":"2022-07-12T13:50:15.292842Z","shell.execute_reply.started":"2022-07-12T13:49:52.280472Z","shell.execute_reply":"2022-07-12T13:50:15.291896Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"history_dict = history.history\nhistory_dict.keys()","metadata":{"execution":{"iopub.status.busy":"2022-07-12T13:50:49.012471Z","iopub.execute_input":"2022-07-12T13:50:49.012905Z","iopub.status.idle":"2022-07-12T13:50:49.020532Z","shell.execute_reply.started":"2022-07-12T13:50:49.012873Z","shell.execute_reply":"2022-07-12T13:50:49.019405Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"#훈련과 검증 손실 그리기\nimport matplotlib.pyplot as plt\n\nhistory_dict = history.history\nloss = history_dict['loss']\nval_loss = history_dict['val_loss']\n\nepochs = range(1, len(loss) + 1)\n\nplt.plot(epochs, loss, 'bo', label='Training loss')  # ‘bo’는 파란색 점을 의미합니다.\nplt.plot(epochs, val_loss, 'b', label='Validation loss') # ‘b’는 파란색 실선을 의미합니다.\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-12T13:51:19.213304Z","iopub.execute_input":"2022-07-12T13:51:19.214380Z","iopub.status.idle":"2022-07-12T13:51:19.490351Z","shell.execute_reply.started":"2022-07-12T13:51:19.214309Z","shell.execute_reply":"2022-07-12T13:51:19.489097Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"# 훈련과 검증 정확도 그리기\nplt.clf() # 그래프를 초기화합니다.\nacc = history_dict['acc']\nval_acc = history_dict['val_acc']\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-12T13:51:47.690522Z","iopub.execute_input":"2022-07-12T13:51:47.691602Z","iopub.status.idle":"2022-07-12T13:51:47.910277Z","shell.execute_reply.started":"2022-07-12T13:51:47.691559Z","shell.execute_reply":"2022-07-12T13:51:47.908997Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":"훈련 손실은 감소하고 훈련 정확도는 상승하는데, 검증 손실이랑 검증 정확도는 딱히,,,\n\n 과대적합!\n \n 그래프를 보니까 3번째 에포크에서부터 검증 정확도가 떨어지고 있다. ","metadata":{}},{"cell_type":"code","source":"#처음부터 다시 훈련하기. 근데 에포크를 4번까지만\nmodel = models.Sequential()\nmodel.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\nmodel.add(layers.Dense(16, activation='relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer='rmsprop',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nnew = model.fit(x_train, y_train, epochs=4, batch_size=512)\nresults = model.evaluate(x_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2022-07-12T13:56:58.152794Z","iopub.execute_input":"2022-07-12T13:56:58.153701Z","iopub.status.idle":"2022-07-12T13:57:05.970064Z","shell.execute_reply.started":"2022-07-12T13:56:58.153659Z","shell.execute_reply":"2022-07-12T13:57:05.969096Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"results\n#정확도가 훨씬 높아짐!!","metadata":{"execution":{"iopub.status.busy":"2022-07-12T13:55:36.407011Z","iopub.execute_input":"2022-07-12T13:55:36.407385Z","iopub.status.idle":"2022-07-12T13:55:36.413712Z","shell.execute_reply.started":"2022-07-12T13:55:36.407354Z","shell.execute_reply":"2022-07-12T13:55:36.412958Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"model.predict(x_test)\n#어떤 리뷰가 긍정일 확률\n#어떤 샘플엔 확신(0.99나 0.01)을 가지고 있지만 어떤 샘플에 대해선 확신이 부족하다.(0.6 0.4...)","metadata":{"execution":{"iopub.status.busy":"2022-07-12T13:58:33.790146Z","iopub.execute_input":"2022-07-12T13:58:33.790544Z","iopub.status.idle":"2022-07-12T13:58:36.538079Z","shell.execute_reply.started":"2022-07-12T13:58:33.790508Z","shell.execute_reply":"2022-07-12T13:58:36.536669Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"#은닉층의 갯수를 다르게 한다면 테스트 정확도가 높아질까?\n#손실 함수를 다른 걸 써볼까?\n#활성화 함수를 다른 걸 써볼까?","metadata":{"execution":{"iopub.status.busy":"2022-07-12T14:00:32.992950Z","iopub.execute_input":"2022-07-12T14:00:32.993403Z","iopub.status.idle":"2022-07-12T14:00:32.997850Z","shell.execute_reply.started":"2022-07-12T14:00:32.993369Z","shell.execute_reply":"2022-07-12T14:00:32.996761Z"},"trusted":true},"execution_count":59,"outputs":[]}]}